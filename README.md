# 《机器学习实战》


## 章节目录

基础：第 1 章

分类： 第 1～7 章

预测：第 8～9 章

无监督式学习：第 10 章

降维与分布式：第 13～14 章


**1 机器学习基础**

- 1.1 Python 基础知识，Numpy、pandas、Matplotlib 等库的简介

- 1.2 开发环境的搭建：Python3 + Anaconda + Jupyter Notebook


**2 k-近邻算法**

- 2.1 k-近邻算法概述

- 2.2 示例：使用 k-近邻算法改进网站的配对效果

- 2.3 示例：手写识别系统


**3 决策树**

- 3.1 决策树的构造

- 3.3 测试和存储分类器

- 3.4 示例：使用决策树预测隐形眼镜类型


**4 基于概率论的分类方法：朴素贝叶斯**

- 4.1 基于贝叶斯决策理论的分类方法

- 4.2 条件概率

- 4.3 使用条件概率来分类

- 4.4 使用朴素贝叶斯进行文档分类

- 4.5 使用 Python 进行文本分类

- 4.6 示例：使用朴素贝叶斯过滤垃圾邮件


**5 Logistic回归**

- 5.1 基于 Logistic 回归和 Sigmoid 函数的回归

- 5.2 基于最优化方法的最佳回归系数确定

- 5.3 示例：从疝气病症预测病马的死亡率


**6 支持向量机**

- 6.1 基于最大间隔分隔数据

- 6.2 寻找最大间隔

- 6.3 SMO 高效优化算法

- 6.4 利用完整 Platt SMO 算法加速优化

- 6.5 在复杂数据上应用核函数

- 6.6 手写识别问题


**7 利用 AdaBoost 元算法提高分类性能**

- 7.1 基于数据 多重抽样的分类器

- 7.2 训练算法：基于错误提升分类器的性能

- 7.3 基于单层决策树构建弱分类器

- 7.4 完整 AdaBoost 算法的实现

- 7.5 测试算法：基于 AdaBoost 的分类

- 7.6 示例：在一个难数据集上应用 AdaBoost

- 7.7 非均衡分类问题


**8 预测数值型数据：回归**

- 8.1 用线性回归找到最佳拟合直线

- 8.2 局部加权线性回归

- 8.3 示例：预测鲍鱼的年龄

- 8.4 缩减系数来“理解”数据

- 8.5 权衡偏差和方差


**9 树回归**

- 9.1 复杂数据的局部性建模

- 9.2 连续和离散型特征的树的构建

- 9.3 将 CART 算法用于回归

- 9.4 树减枝

- 9.5 模型树

- 9.6 示例：树回归于标准回归的比较


**10 利用 K-均值聚类算法对未标注数据分组**

- 10.1 K-均值聚类算法

- 10.2 使用后处理来提高聚类性能

- 10.3 二分 K-均值算法

- 10.4 示例：对地图上的点进行聚类


**11　使用Apriori算法进行关联分析**
 - 11.1 　关联分析
 - 11.2 　Apriori原理
 - 11.3 　使用Apriori算法来发现频繁集
 - 11.4 　从频繁项集中挖掘关联规则
 - 11.6 　示例：发现毒蘑菇的相似特征

 
**12　使用FP-growth算法来高效发现频繁项集**
 - 12.1 　FP树：用于编码数据集的有效方式
 - 12.2 　构建FP树
 - 12.3 　从一棵FP树中挖掘频繁项集
 - 12.5 　示例：从新闻网站点击流中挖掘


**13 利用PCA来简化数据**

- 13.1 降纬技术

- 13.2 PCA

- 13.3 示例：利用 PCA 对半导体制造数据降维


**14 利用SVD简化数据**

- 14.1 SVD 的应用

- 14.2 矩阵分解

- 14.3 利用 Python 实现 SVD

- 14.4 基于协调过滤的推荐引擎

- 14.5 示例：餐馆菜肴推荐引擎

- 14.6 示例：基于 SVD 的图像压缩


**15　大数据与MapReduce**
 - 15.1 　MapReduce：分布式计算的框架
 - 15.2 　Hadoop流
  - 15.2.1 　分布式计算均值和方差的mapper
  - 15.2.2 　分布式计算均值和方差的reducer
