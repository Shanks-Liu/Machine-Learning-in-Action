decision-making-tree
=====

决策树
----
__优点__： 计算复杂度不高，输出结果易于理解，对中间值缺失不敏感，可以处理不相关特征数据  
__缺点__： 可能会过拟合  
__适用数据类型__： 数值型和标称型  

决策树算法伪代码
----
检测数据集中的每个子项是否属于同一分类：  
　　if Ture:  
　　　　return 类标签  
　　else:  
　　　　寻找信息增益最高的特征  
　　　　划分数据集  
　　　　创建分支节点  
　　　　　　for 每个划分的子集：  
　　　　　　　　调用本函数并增加结果到分支节点中  
　　　　return 分支节点  

1. 定义一个计算熵的函数：接收数据集， 返回熵值。  
2. 定义一个划分数据集的函数： 接收数据集，轴，值， 返回划分后的子集。  
3. 定义一个找到一个最优特征（信息增益最高）的函数： 接收数据集， 返回最优特征的索引。  
4. 定义一个创建数的函数： 接收数据集，特征标签列表， 返回树。  
